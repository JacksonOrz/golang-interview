# 消息队列

### 消息队列的两种模式

- **点对点模式**（一对一，消费者主动拉取数据，消息收到后消息清除）
  - 生产者生产消息发送到Queue中，然后消费者从Queue中取出并且消费消息。消息被消费以后，queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。
- **发布订阅模式**（一对多，消费者消费数据之后不会清除消息）
  - 生产者将消息**发布**到 topic 中，同时有多个消费者**订阅**该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。
  - Kafka 采取拉取模型，由自己控制消费速度，以及消费的进度，消费者可以按照任意的偏移量进行消费。

### 为什么要使用消息队列？

主要有三个核心场景：**解耦**、**异步**、**削峰**。

### 消息队列有什么缺点？

- 系统可用性降低
  - 系统引入的外部依赖越多，越容易挂掉
- 系统复杂度提高
  - 要保证消息没有重复消费、处理消息丢失的情况、保证消息传递的顺序性
- 一致性问题
  - A 系统处理完了直接返回成功了，但是BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，导致数据就不一致

## Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么区别？

| 特性                     | ActiveMQ                              | RabbitMQ                                           | RocketMQ                                                     | Kafka                                                        |
| ------------------------ | ------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 开发语言                 | java                                  | erlang                                             | java                                                         | scala                                                        |
| 单机吞吐量               | 万级，比 RocketMQ、Kafka 低一个数量级 | 同 ActiveMQ                                        | 10 万级，支撑高吞吐                                          | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响 |                                       |                                                    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                   | ms 级                                 | 微秒级，这是 RabbitMQ 的一大特点，延迟最低         | ms 级                                                        | 延迟在 ms 级以内                                             |
| 可用性                   | 高，基于主从架构实现高可用            | 同 ActiveMQ                                        | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性               | 有较低的概率丢失数据                  | 基本不丢                                           | 经过参数优化配置，可以做到 0 丢失                            | 同 RocketMQ                                                  |
| 功能支持                 | MQ 领域的功能极其完备                 | 基于 erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好                      | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |
| 社区活跃度               | 低                                    | 很高                                               | 一般                                                         | 很高                                                         |

# kafka

### 基本架构

![img](https://camo.githubusercontent.com/5170e60c546d22a3cfa92f8f3e2992cacdedc40d099f189b4c15e08fb35d7b32/687474703a2f2f696d672e676f646a6979692e636e2f6373646e626c6f676b61666b612d6172632e6a7067)

Kafka 集群由多个 broker 组成，每个 broker 是一个节点。你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。

##### Topic（主题）

Topic 是一个存储消息的逻辑概念，可以认为是一个消息集合。每条消息发送到 Kafka 集群的消息都有一个类别，这个类别就是 Topic。

不同的生产者将不同的业务消息分发到不同的 **topic** 上，这样消费者就可以根据 **topic** 进行对应的业务消息消费了。

每个 Topic 可以有多个生产者向它发送消息，也可以有多个消费者去消费其中的消息。

##### Broker

- 一个 broker 就是一个 kafka 节点，多个 broker 构成一个 kafka 集群。

#### Partition（分区）

- 一个**主题**分成多个**分区**，一个**分区**只属于单个**主题**，，很多时候也会把分区称为主题分区（Topic-Partition），每个 partition 是一个有序的消息序列
- 同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）
- 多个 **producer** 生产消息可以并行入队，多个 **consumer** 可并行消费
- 同一个partition里保证消息有序，不同partition则不能完全保证有序
  - offset 是消息在分区中的唯一标识，Kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区，也就是说，Kafka 保证的是分区有序而不是主题有序。

> 选择分区的原则
>
> 1. 指定了 partition
> 2. 没有指定 partition 但设置了 key，则根据 key 的值 hash 出一个 partition
> 3. 没有指定分区，没有设置 key，则轮询各分区发送，即每次取一小段时间的数据写入某个 partition，下一小段时间的数据写入下一个 partition

#### Replica

Replica（副本）指的是一个分区（Partition）的备份。

[![img_7654f69f203c098f49c7054dc84fc1b9.png](https://camo.githubusercontent.com/5977ee509001fc5756fb4535d1d65d08dccfdd1486cff5f858e55864b6354ffb/68747470733a2f2f797166696c652e616c6963646e2e636f6d2f696d675f37363534663639663230336330393866343963373035346463383466633162392e706e67)](https://camo.githubusercontent.com/5977ee509001fc5756fb4535d1d65d08dccfdd1486cff5f858e55864b6354ffb/68747470733a2f2f797166696c652e616c6963646e2e636f6d2f696d675f37363534663639663230336330393866343963373035346463383466633162392e706e67)

简单的replica分配示意图（圆角矩形代表replica）

这种分配保证了，任何一台机器挂掉，kafka集群依然有备份可用。

分为 **Leader**（主节点，1） 和 **Follower**（从节点，N）两种角色。

生产者发送数据的对象，以及消费者消费数据的对象都是 leader。

follower 实时从 leader 中同步数据，保持和 leader 数据的同步。leader 发生故障时，某个 follower 会成为新的 leader。

#### Consumer Group

消费者组就是消费者组成的一个组，消费者在向 Kafka 拉取（pull）数据的时候需要提供一个组名，这个名称就是消费者组名。两种消息模式都可以在消费者组中得到实现。

> consumer 采用 pull（拉）模式从 broker 中读取数据。
>
> push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。而 pull 模式则可以根据 consumer的消费能力以适当的速率消费消息。

1. **点对点/队列模式**：一个消息只能被一个消费者消费，我们只需要将这些消费者放在同一个消费者组里就可以了，这样消费者在同一个组中，那么 topic 中的一条消息只会向一个消费者组发送一次；
2. **发布-订阅模式**：一个消息可被多个消费者消费，这种情况，我们只需要将各个消费者放在各自单独的组中，各个组均订阅了此消息 topic 就可以了。

注意点：

- 一个消费组消费一个 **topic** 的全量数据；
- 组内消费者消费一个或多个 **partition** 数据，如果一个组里的消费者数量少于订阅的 topic 的 partition 数量，那么组中必有一个消费者要消费多个 partion 数据；
- 一个组里的消费者应小于等于 **topic** 的 **partition** 数量，这是因为一个 partition 最多只能与一个 consumer 连接，那么如果 partition 数量大于 consumer 数量，则必定有 consumer 是空闲的，因此尽量避免这种情况；

### Kafka 的特点

1. **高吞吐量**：Kafka 能够处理大量的数据流，适用于实时数据管道和事件流处理。
2. **高可用性**：通过分区和复制机制，Kafka 能够保证高可用性和数据冗余。
3. **持久化存储**：Kafka 使用磁盘存储消息，支持持久化和回放。
4. **水平扩展**：Kafka 通过增加 broker 实现水平扩展，处理更大的数据量和并发。

### Kafka 的常见使用场景

1. **实时数据流**：实时日志收集和分析、监控数据流处理。
2. **事件驱动架构**：系统间的事件通知和消息传递。
3. **数据集成**：不同数据源间的数据同步和集成。
4. **日志和指标收集**：集中收集应用程序日志和指标，进行实时分析。

### Kafka 如何保证高可用？

 `replica` 副本机制。每个 `partition` 上的数据都会同步到其它机器，形成自己的多个 `replica` 副本。所有 `replica` 会选举一个 `leader` 出来，消息的生产者和消费者都跟这个 `leader` 打交道，其他 `replica` 作为 `follower`。写的时候，`leader` 会负责把数据同步到所有 `follower` 上去，读的时候就直接读 `leader` 上的数据即可。`Kafka` 负责均匀的将一个 `partition` 的所有 `replica` 分布在不同的机器上，这样才可以提高容错性。

拥有了 `replica` 副本机制，如果某个 `broker` 宕机了，这个 `broker` 上的 `partition` 在其他机器上还存在副本。如果这个宕机的 `broker` 上面有某个 `partition` 的 `leader`，那么此时会从其 `follower` 中重新选举一个新的 `leader` 出来，这个新的 `leader` 会继续提供读写服务，这就有达到了所谓的高可用性。

写数据的时候，生产者只将数据写入 `leader` 节点，`leader` 会将数据写入本地磁盘，接着其他 `follower` 会主动从 `leader` 来拉取数据，`follower` 同步好数据了，就会发送 `ack` 给 `leader`，`leader` 收到所有 `follower` 的 `ack` 之后，就会返回写成功的消息给生产者。

消费数据的时候，消费者只会从 `leader` 节点去读取消息，但是只有当一个消息已经被所有 `follower` 都同步成功返回 `ack` 的时候，这个消息才会被消费者读到。

### Kafka 消息是采用 Pull 模式，还是 Push 模式？

生产者使用push模式将消息发布到Broker，消费者使用pull模式从Broker订阅消息。

push模式很难适应消费速率不同的消费者，如果push的速度太快，容易造成消费者拒绝服务或网络拥塞；如果push的速度太慢，容易造成消费者性能浪费。但是采用pull的方式也有一个缺点，就是当Broker没有消息时，消费者会陷入不断地轮询中，为了避免这点，kafka有个参数可以让消费者阻塞知道是否有新消息到达。

### 在Kafka中，ZooKeeper的作用是什么？

目前，Kafka使用ZooKeeper存放集群元数据、成员管理、Controller选举，以及其他一些管理类任务。之后，等KIP-500提案完成后，Kafka将完全不再依赖于ZooKeeper。

- “存放元数据”是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他 “人” 都要与它保持对齐。
- “成员管理” 是指 Broker 节点的注册、注销以及属性变更，等等。
- “Controller 选举” 是指选举集群 Controller，而其他管理类任务包括但不限于主题删除、参数配置等。

KIP-500 思想，是使用社区自研的基于Raft的共识算法，替代ZooKeeper，实现Controller自选举。

### Kafka是如何实现高吞吐的？or Kafka为什么那么快？

- 零拷贝技术
  - Kafka在读写数据时使用了零拷贝技术，即将数据直接从磁盘读入内核缓冲区，避免了一次次的内存拷贝和系统调用，提高了IO效率。
- 页缓存技术 + 磁盘顺序写
- 分区分段
  - Kafka的message是按topic分类存储的，topic中的数据又是按照一个一个的partition即分区存储到不同broker节点。每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的。这也非常符合分布式系统分区分桶的设计思想。
- 批量发送和消费
  - Kafka支持批量发送和消费消息，生产者可以将多个消息批量发送到Kafka集群，消费者可以一次性从多个分区中拉取多个消息进行消费，减少了网络传输次数和磁盘IO次数。

### kafka producer发送数据，ack为0，1，-1分别是什么意思？

- `0` 生产者将数据发送出去就不管了，不去等待任何返回。这种情况下数据传输效率最高，但是数据可靠性确是最低的。

- `1`（默认） 数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。在这种情况下，如果leader宕机了，则会丢失数据。

- `-1`producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。当ISR中所有Replica都向Leader发送ACK时，leader才commit，这时候producer才能认为一个请求中的消息都commit了。

### Kafka如何保证消息不丢失？

首先需要弄明白消息为什么会丢失，对于一个消息队列，会有 `生产者`、`MQ`、`消费者` 这三个角色，在这三个角色数据处理和传输过程中，都有可能会出现消息丢失。

[![img](https://camo.githubusercontent.com/5c409147c59681e4380d557ecc6472adf9872cd4a45e495df58c658cfd1dbd0b/687474703a2f2f626c6f672d696d672e636f6f6c73656e2e636e2f696d672f536f6c76652d4d512d50726f626c656d2d576974682d4b61666b612d30332e706e672369643d66794a5641266f726967696e4865696768743d343431266f726967696e57696474683d31343239266f726967696e616c547970653d62696e61727926726174696f3d3126726f746174696f6e3d302673686f775469746c653d66616c7365267374617475733d646f6e65267374796c653d6e6f6e65267469746c653d)](https://camo.githubusercontent.com/5c409147c59681e4380d557ecc6472adf9872cd4a45e495df58c658cfd1dbd0b/687474703a2f2f626c6f672d696d672e636f6f6c73656e2e636e2f696d672f536f6c76652d4d512d50726f626c656d2d576974682d4b61666b612d30332e706e672369643d66794a5641266f726967696e4865696768743d343431266f726967696e57696474683d31343239266f726967696e616c547970653d62696e61727926726174696f3d3126726f746174696f6e3d302673686f775469746c653d66616c7365267374617475733d646f6e65267374796c653d6e6f6e65267469746c653d)

消息丢失的原因以及解决办法：

#### 消费者异常导致的消息丢失

**消费者可能导致数据丢失的情况是**：消费者获取到了这条消息后，还未处理，`Kafka` 就自动提交了 `offset`，这时 `Kafka` 就认为消费者已经处理完这条消息，其实消费者才刚准备处理这条消息，这时如果消费者宕机，那这条消息就丢失了。

消费者引起消息丢失的主要原因就是消息还未处理完 `Kafka` 会自动提交了 `offset`，那么只要关闭自动提交 `offset`，消费者在处理完之后手动提交 `offset`，就可以保证消息不会丢失。但是此时需要注意重复消费问题，比如消费者刚处理完，还没提交 `offset`，这时自己宕机了，此时这条消息肯定会被重复消费一次，这就需要消费者根据实际情况保证**幂等性**。

#### 生产者数据传输导致的消息丢失

对于生产者数据传输导致的数据丢失主常见情况是生产者发送消息给 `Kafka`，由于网络等原因导致消息丢失，对于这种情况也是通过在 **producer** 端设置 **acks=all** 来处理，这个参数是要求 `leader` 接收到消息后，需要等到所有的 `follower` 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试。

#### Kafka 导致的消息丢失

`Kafka` 导致的数据丢失一个常见的场景就是 `Kafka` 某个 `broker` 宕机，而这个节点正好是某个 `partition` 的 `leader` 节点，这时需要重新重新选举该 `partition` 的 `leader`。如果该 `partition` 的 `leader` 在宕机时刚好还有些数据没有同步到 `follower`，此时 `leader` 挂了，在选举某个 `follower` 成 `leader` 之后，就会丢失一部分数据。

对于这个问题，`Kafka` 可以设置如下 4 个参数，来尽量避免消息丢失：

- 给 `topic` 设置 `replication.factor` 参数：这个值必须大于 `1`，要求每个 `partition` 必须有至少 `2` 个副本；
- 在 `Kafka` 服务端设置 `min.insync.replicas` 参数：这个值必须大于 `1`，这个参数的含义是一个 `leader` 至少感知到有至少一个 `follower` 还跟自己保持联系，没掉队，这样才能确保 `leader` 挂了还有一个 `follower` 节点。
- 在 `producer` 端设置 `acks=all`，这个是要求每条数据，必须是写入所有 `replica` 之后，才能认为是写成功了；
- 在 `producer` 端设置 `retries=MAX`（很大很大很大的一个值，无限次重试的意思）：这个参数的含义是一旦写入失败，就无限重试，卡在这里了。

### Kafka如何保证消息不重复消费

导致重复消费的原因可能出现在生产者，也可能出现在 MQ 或 消费者。

这里说的重复消费问题是指同一个数据被执行了两次，不单单指 MQ 中一条消息被消费了两次，也可能是 MQ 中存在两条一模一样的消费。

- 生产者：生产者可能会重复推送一条数据到 MQ 中，为什么会出现这种情况呢？也许是一个 Controller 接口被重复调用了 2 次，没有做接口幂等性导致的；也可能是推送消息到 MQ 时响应比较慢，生产者的重试机制导致再次推送了一次消息。
- MQ：在消费者消费完一条数据响应 ack 信号消费成功时，MQ 突然挂了，导致 MQ 以为消费者还未消费该条数据，MQ 恢复后再次推送了该条消息，导致了重复消费。
- 消费者：消费者已经消费完了一条消息，正准备但是还未给 MQ 发送 ack 信号时，此时消费者挂了，服务重启后 MQ 以为消费者还没有消费该消息，再次推送了该条消息。

消费者怎么解决重复消费问题呢？这里提供两种方法：

- 状态判断法：消费者消费数据后把消费数据记录在 redis 中，下次消费时先到 redis 中查看是否存在该消息，存在则表示消息已经消费过，直接丢弃消息。
- 业务判断法：通常数据消费后都需要插入到数据库中，使用数据库的唯一性约束防止重复消费。每次消费直接尝试插入数据，如果提示唯一性字段重复，则直接丢失消息。一般都是通过这个业务判断的方法就可以简单高效地避免消息的重复处理了。

### 解决kafka消费积压问题

消费积压就是产生的数据堆积没有实时消费数据。比如一分钟消费1000条，但是每分钟会产生2000条消息，就会存在1000条的积压。

积压造成的原因，基本都可以定位为消费能力不足。

对Kafka的消费主要是三部分向Kafka拿数据，对拿到的数据进行计算和对计算后的数据进行输出。

向Kafka拿数据很难成为瓶颈，因为Kafka磁盘顺序读写，顺序读写的速度都是远大于随机读写的。

对拿到的数据进行计算主要是业务部分，看是否能优化时间复杂度。

将计算后的数据输出，通常写入目标数据库表，随着写入数据量的越来越多，排序消耗的时间理论上也会越来越长。

#### 解决方案

针对不同的问题，解决办法需要对症下药。

1、计算复杂度过高：需要优化计算逻辑

- 对计算逻辑进行优化，可能涉及到算法改进、减少不必要的计算步骤、降低时间复杂度等。
- 使用更高效的数据结构和算法，以提高计算效率。

2、计算过程中涉及到的高IO操作：需要将额外的数据源提前加载到内存中

- 将频繁的、高IO的数据源提前加载到内存中，减少对外部数据的实时读取次数。
- 使用缓存机制，避免重复读取相同的外部数据。

3、数据库写入端太慢

- 增加写入缓冲区的大小，以减少写入数据库的频次。
- 优化写入过程，将多次的频繁写入操作优化为批量写入，减少数据库事务的开销。
- 增加写入端的并行度，考虑将单机表优化为分布式表，以提高整体写入性能。

4、增加 Kafka Topic的 Partition 数量（提高消费端并行度，仅限于不涉及以上三个瓶颈时）

- 增加要处理的 Kafka Topic 的 Partition 数量，这样消费程序就能够以更大的并行度来处理数据。
- 每个 Partition 对应一个独立的消费者，从而提高整体消费能力。

### Kafka 分区的目的和作用

Kafka的分区是指将Kafka Topic中的消息分散到多个分区中。分区的主要目的是实现消息的并行处理，提高Kafka的吞吐量和性能。

### Kafka如何保证消息有序性

两种方案：

- 方案一：kafka topic 只设置一个 partition 分区
- 方案二：producer 将消息发送到指定同一个 partition 分区

方案一：kafka 默认保证同一个 partition 分区内的消息是有序的，则可以设置 topic 只使用一个分区，这样消息就是全局有序，缺点是只能被 consumer group 里的一个消费者消费，降低了性能，不适用高并发的情况。

方案二：既然 kafka 默认保证同一个 partition 分区内的消息是有序的，则 producer 可以在发送消息时可以指定需要保证顺序的几条消息发送到同一个分区，这样消费者消费时，消息就是有序。

![方案二](https://camo.githubusercontent.com/4a82d30cbd735bf9b76724f495b95a1f23ce58d966e3964036dbe353c85f1974/68747470733a2f2f696d67323031382e636e626c6f67732e636f6d2f692d626574612f3732373630322f3230323030312f3732373630322d32303230303131333135353630303835372d313232373831393332382e706e67)

**
总结：每个分区内的消息是有序的，而消费者组确保每个分区只由一个消费者处理，从而保证了消费整体上的顺序性。**

### 为什么Kafka不支持读写分离？

在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。

Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:

- **数据一致性问题**。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。
- **延时问题**。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历`网络→主节点内存→网络→从节点内存`这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历`网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘`这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。

### # 请谈一谈 Kafka 数据一致性原理（高水位机制，现在用的是Leader Epoch机制）

一致性就是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。

假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，**而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区**，对应于上图的副本2，这个很类似于木桶原理。

这样做的原因是还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。

当然，引入了 High Water Mark 机制，会导致 Broker 间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长（因为我们会先等待消息复制完毕）。延迟时间可以通过参数 [replica.lag.time.max.msopen in new window](http://replica.lag.time.max.ms) 参数配置，它指定了副本在复制消息时可被允许的最大延迟时间。