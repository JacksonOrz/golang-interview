# Mysql基础

### CHAR 和 VARCHAR有什么区别？

char是固定长度的字符串类型，定义时需要指定固定长度，存储时会在末尾补足空格。char适合存储固定长度的数据，如固定长度的代码，状态等。

varchar是可变长的字符串类型，定义时需要指定最大长度，实际存储时根据实际长度占用存储空间。varchar适合存储长度不固定可变的数据，如用户输入的文本等。

### in和exists的区别

in用于检查左边的表达式是否存在于**右边的列表**或子查询的结果集中。如果存在，则in返回true，否则返回false。

exists用于判断**子查询**是否至少能返回一行数据。它不关心返回什么数据，只关心是否有结果。有就返回true否则false。

### IP地址如何在数据库里存储？

1、以字符串的形式存储，

优点：直观易懂，方便直接进行数据的插入、查询和显示，不需要进行额外的转换操作。

缺点：占用存储空间较大，字符串比较操作的性能相对较低，不利于进行范围查询。

2、以整数来存储

### 数据库三大范式是什么？

第一范式（1NF）：要求数据库表的**每一列都是不可分割的原子数据项**        

第二范式（2NF）：在1NF的基础上，**非码属性必须完全依赖于候选码**（在1NF基础上消除非主属性对主码的部分函数依赖)

第三范式（3NF）：在2NF基础上，**任何非主属性不依赖于其它非主属性**（在2NF基础上消除传递依赖)        

### 执行一条SQL请求的过程是什么？

1. 客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求进行权限验证及连接资源分配

2. 查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。）

3. 语法分析（SQL 语法是否写错了）。 如何把语句给到预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义。

4. 优化。是否使用索引，生成执行计划。

5. 交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。

   **执行语句前会先校验一下当前用户是否有表的执行权限，如果没有权限会直接报错。当用户有权限操作时，执行器会根据存储引擎去调用对一个接口。**

   **执行器的执行流程：（无索引）**

   - **innodb引擎接口取出这个表的第一行，判断id值是是否符合要求，不符合跳过，符合将结果存储**
   - **继续调用存储引擎接口取下一条，重复，直至取到最后表最后一行**
   - **将所有满足条件的数据组成最终的结果集返回。**

   **对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”的这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。**

![image.png](https://camo.githubusercontent.com/8391a29bef49d889d2a5cfadc4a0c0d56d7f59cb285c62ed036a03fb62572600/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032322f706e672f32323231393438332f313634373136303334353836362d32653933323235632d356539392d346161352d613262392d3736346331636265663233622e706e6723617665726167654875653d25323365396563646626636c69656e7449643d7534346632626138662d316466652d342666726f6d3d70617374652669643d756665376165363464266f726967696e4865696768743d343332266f726967696e57696474683d353736266f726967696e616c547970653d75726c26726174696f3d3126726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d323133303536267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7564363631346266312d373665662d346132362d613830622d3239656637643361363766267469746c653d)

### SQL查询语句的执行顺序是怎么样的？

SQL 的实际执行顺序是：FROM → WHERE → GROUP BY → HAVING → SELECT → DISTINCT → ORDER BY → LIMIT，这解释了为什么 WHERE 不能用聚合函数，而 HAVING 可以。

### 讲一讲mysql的引擎吧，你有什么了解？or（mysql的存储引擎之间有什么区别？）

InnoDB：InnoDB是mysql 的默认存储引擎，支持**ACID****事务，行级锁，****外键****约束**等特性。它适用于**高并发的读写操作**。具有较好的数据完整性和并发控制。

myisam：是mysql的另一种常见的存储引擎，具有较低的存储空间和内存消耗，**适用于大量读操作的场景**。但是不支持ACID事务，行级锁，外键约束等特性。因此在数据完整性和并发写入方面有一定的限制。

memory：Memory引擎将**数据存储在****内存****中**，适用于**对性能要求较高的读操作**，但是在服务器**重启****或崩溃**时数据会丢失。它不支持事务、行级锁和外键约束。

### MySQL为什么InnoDB是默认引擎？

InnoDB引擎在**事务支持、并发性能、崩溃恢复**等方面具有优势，因此被MySQL选择为默认的存储引擎。

·事务支持：InnoDB引擎提供了对事务的支持，可以进行ACID（原子性、一致性、隔离性、持久性）属

性的操作。Myisam存储引擎是不支持事务的。

·并发性能：InnoDB引擎采用了行级锁定的机制，可以提供更好的并发性能，Myisam存储引擎只支持表

锁，锁的粒度比较大。

·崩溃恢复：**InnoDB引擎通过redolog 日志实现了崩溃恢复**，可以在数据库发生异常情况(如断电)

时，通过日志文件进行恢复，保证数据的持久性和一致性。Myisam是不支持崩溃恢复的。

### 说一下mysql的Innodb与MyISAM的区别？(事务，索引，锁粒度，count效率)

1、Innodb支持事务，而MyISAM不支持事务。

2、nnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。

3、Innodb最小的锁粒度是行锁，MyISAM最小的锁粒度是表锁。

4、InnoDB 不保存表的具体行数，MyISAM 用一个变量保存了整个表的行数。

5、InnoDB不支持全文索引，而MyISAM支持全文索引，查询效率上要比MyISAM高。

# 事务

### 事务的特性有哪些？如何实现的？

**原子性：**一个事务中的所有操作，要么都做要么都不做。通过undo日志来保证的。

**一致性：**是指事务操作前后，数据满足完整性约束，数据库保持一致性状态。通过其他三个特性来保证的

**隔离性：**事务的隔离性是指**一个事务的执行不能被其他事务干扰** ，即一个事务内部的操作及使用的数据对并发 的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；

**持久性：**事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 通过redo日志来实现的。

### 什么是脏读？不可重复读？幻读？

1、脏读：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据 

2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果 不一致。 

3、幻读：系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 不可重复读侧重于修改，幻读侧重于新增或删除（多了或少量行），脏读是一个事务回滚影响另外一个事务。

### 事务有哪几种隔离级别？

读未提交（啥都解决不了）

读已提交（解决脏读）

可重复读（默认隔离级别，解决脏读和不可重复读）

串行化

通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

### 事务的实现原理

事务是基于重做日志文件(redo log)和回滚日志(undo log)实现的。 每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。 每当有修改事务时，还会产生 undo log，如果需要回滚，则根据 undo log 的反向语句进行逻辑操作，比如 insert 一条记录就 delete 一条记录。undo log 主要实现数据库的一致性。

### mysql的是怎么解决并发问题的？

1、锁机制：mysql提供了多种锁机制来保证数据的一致性，包括行级锁、表级锁、页级锁等。通过锁机制，可以在读写操作时对数据进行加锁，确保同时只有一个操作能够访问或修改数据。

2、事务隔离级别：mysql提供了多种事务隔离级别，包括读未提交、读已提交、可重复读和串行化。通过设置合适的事务隔离级别，可以在多个事务并发执行时，控制事务之间的隔离程度，以避免数据不一致的问题。

3、使用MVCC（多版本并发控制）：mysql使用MVCC来管理并发访问，它通过在数据库中**保存不同版本的数据**来实现不同事务的隔离。 

### 举个例子说可重复读下的幻读问题。

幻读是指：在一个事务中，两次执行相同的范围查询，但第二次查询看到了第一次不存在的”新插入“的行。虽然Mysql的Innodb在可重复读隔离级别下通过行级锁和间隙锁解决了大部分幻读问题，但仅在快照读（普通select）而**没有加锁的场景**下，如果配合写操作，仍可能出现幻读。例如有一张id和姓名的表，事务A两次查id>0的记录，而在这两次中间事务B往表中插入了一条新记录。当事务A这时去更新其中的某条记录后再去查就会发现多一条新记录。这就是幻读。 因为**update是当前读（current read），它会读取最新数据并加锁**，从而“看到”了新插入的行，并将其更新。**如果要避免，可以在查询时显示加锁。**

### 介绍MVCC实现原理

在InnoDB里，MVCC主要是通过多版本数据来实现并发控制的，让读写不阻塞。首先每一行会有两个隐藏字段：一个是最近修改它的事务id；另一个是指向undolog中这行旧版本的指针。当事务第一次读取数据时，会生成一个read view，里面记录当前活跃事务的id列表。这个read view用来判断某个版本的数据对当前事务的可见性。判断逻辑是这样的：如果行的最近修改事务id小于readView里最小活跃事务id，那么说明这行数据对应的事务已提交，可见；如果最近修改事务id还在活跃列表里，就说明它未提交，不可见，就沿着指针回到undolog查找旧版本。写操作时，先将该行修改前的状态记录放到Undolog中，然后覆盖旧数据**并更新当前行的最近修改事务id**。后面还有个purge线程会清理掉不再被任何活跃事务引用的旧版本，避免占用空间。这样一来，读操作就可以读到自己一致性视图下的版本，不会被别的事务写操作阻塞，实现了高并发。

### MySQL三大日志

**undoLog**

主要用于事务的回滚操作。当事务执行过程中发生异常或需要回滚时，回滚日志记录了事务的操作信息，可以用于撤销事务对数据库的修改，==实现事务的原子性==。例如，对于每个UPDATE语句，对应一条相反的UPDATE的 undo log。

- 适用场景：事务回滚、MVCC；

**redoLog**

redo log 不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入 redo 中。具体的落盘策略可以进行配置 。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启 MySQL 服务的时候，根据 redo log 进行重做，从而达到事务的未入磁盘数据进行持久化这一特性。

redo log是循环写，日志空间大小固定，会覆盖。==实现事物的持久性。==

- 适用场景：崩溃恢复（crash-safe）

**binlog**

二进制日志记录了所有对数据库的更改操作，包括数据更新、插入、删除等，以便在主从复制时同步数据或进行数据恢复和备份。与 redo log 不同，binlog 是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。主要用于

- 主从复制：在 Master 端开启 binlog ，然后将 binlog 发送到各个 Slave 端， Slave 端重放 binlog 来达到主从数据一致；
- 数据恢复：通过使用 mysql binlog 工具来恢复数据。
- 数据备份

**binlog有三种格式类型：**

STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中

ROW：记录行数据最终被修改成什么样了

MIXED：包含了STATEMENT和ROW模式，它会根据不同的情况自动使用ROW模式和STATEMENT

模式;

#### undo log 是如何刷盘（持久化到磁盘）的

undo log 和数据页的刷盘策略是一样的，都需要通过 redo log 保证持久化。

buffer pool 中有 undo 页，对 undo 页的修改也都会记录到 redo log。redo log 会每秒刷盘，提交事务时也会刷盘，数据页和 undo 页都是靠这个机制保证持久化的。

### binlog 和 redo log 的异同

1. 适用对象不同
   - binlog 是 Server 层实现的，并且 binlog 不仅针对于 InnoDB，所有引擎都可以使用
   - redo log 是 InnoDB 引擎特有的
2. 两者存储格式不同
   - binlog 存储的是逻辑日志，记录了所有数据库表结构变更和表数据修改的日志，如：对xxx表中的id=yyy的行做做了什么修改，更改后的值是什么。binlog 不会记录你的 select 、show 这类的操作。
   - redo log 则记录物理日志，记录的是在某个数据页做了什么修改，如：对哪个数据页的那个记录做了什么修改。
3. 写入方式不同
   - binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。
   - redo log 是循环写的，空间固定会用完，全部写满就从头开始，保存未被刷入磁盘的脏页日志。
4. 触发存储的时间点不同
   - binlog 只在事务提交后才写入一次
   - redo log 则是在整个事务处理的过程中在不断的写入
5. 用途不同
   - binlog 用于备份恢复、主从复制
   - redo log 用于掉电等故障恢复

## redolog怎么保持数据库的持久性的？/redolog如何保证故障恢复的？

Redo log是MySQL中用于保证持久性的重要机制之一。它通过以下方式来保证持久性：

1. Write-ahead logging（WAL）：在事务提交之前，将事务所做的修改操作记录到redo log中，然后再将数据写入磁盘。这样即使在数据写入磁盘之前发生了宕机，系统可以通过redolog中的记录来恢复数据。
2. Redolog的顺序写入：redolog采用顺序追加写入的方式，将redo日志记录追加到文件末尾，而不是随机写入。这样可以减少磁盘的随机I/O操作，提高写入性能。
3. Checkpoint机制：MySQL会定期将内存中的数据刷新到磁盘，同时将最新的日志序列号LSN（Log SequenceNumber）记录到磁盘中，这个LSN可以确保redolog中的操作是按顺序执行的。在恢复数据时，系统会根据日志序列号来确定从哪个位置开始应用redolog。

## 为什么要写RedoLog，而不是直接写到B+树里面？

因为redoLog写入磁盘是顺序写，而b+树里数据页写入磁盘是随机写，顺序写的性能会比随机写好，这样可以**提升事务的提交效率**。最重要的是redolog具备故障恢复的能力。redoLog记录的是**物理位置和修改内容**，数据库重启时，首先根据redolog**检查哪些事务已经提交但数据页尚未完全写入磁盘**。然后使用redolog记录对写事务进行重做操作。

### 两阶段提交

redo log 让 InnoDB 存储引擎拥有 crash-safe 能力; binlog 保证了 MySQL 集群下的数据一致性. redo log 在事务执行过程中可以不断写入, 而 binlog 只有在提交事务时才写入, 两者写入时机不同.

假设有一个事务正在执行, 执行过程中已经写入了 redo log, 而提交完后 binlog写入时发生异常, 那么在 binlog 中可能就没有对应的更新记录, 之后从库使用 binlog 恢复时, 导致少一次更新操作. 而主库用 redo log 进行恢复, 操作则正常. 最终导致这两个库的数据不一致.

于是 InnoDB存储引擎 使用**两阶段提交**方案 : 将 redo log 的写入拆成了两个步骤 **prepare** 和 **commit**

1. 执行事务时写入redo log (这时处于prepare)
2. 提交事务之前, 先写入 binlog
3. 最后提交事务, 并将 redo log 进行 commit

若使用 redo log 恢复数据时, 发现处于 prepare 阶段, 且没有 binlog, 则会回滚该事务. 若 redo log commit 时异常, 但是存在对应 binlog, MySQL还是认为这一组操作是有效的, 并不会进行回滚.

[![image-20220304202100774.png](https://camo.githubusercontent.com/dd09c0273802cc403ee6ea79e85b3d350e02175039961cb2302e03a2bf3a7a23/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032322f706e672f32313338303237312f313634363436383439363137372d33313266616131332d616139652d343536382d626234382d6164336539363066376464392e706e6723617665726167654875653d25323365316537643626636c69656e7449643d7562363366373237382d303933622d342666726f6d3d75692669643d5578366d64266f726967696e4865696768743d363430266f726967696e57696474683d343333266f726967696e616c547970653d62696e61727926726174696f3d3126726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d313431313431267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7534616462373563352d376363382d343763372d613635312d3634633861613264653962267469746c653d)](https://camo.githubusercontent.com/dd09c0273802cc403ee6ea79e85b3d350e02175039961cb2302e03a2bf3a7a23/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032322f706e672f32313338303237312f313634363436383439363137372d33313266616131332d616139652d343536382d626234382d6164336539363066376464392e706e6723617665726167654875653d25323365316537643626636c69656e7449643d7562363366373237382d303933622d342666726f6d3d75692669643d5578366d64266f726967696e4865696768743d363430266f726967696e57696474683d343333266f726967696e616c547970653d62696e61727926726174696f3d3126726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d313431313431267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7534616462373563352d376363382d343763372d613635312d3634633861613264653962267469746c653d)

**总结：**保证两者在事务提交时状态一致，MySQL 采用“两阶段提交”机制：事务提交时，先写入redolog并同时将Redo Log 写入磁盘并标记为 PREPARE 状态，再写 Binlog 并落盘，最后将 Redo Log 改为 COMMIT 状态。若中途崩溃，重启后 MySQL 会扫描 Redo Log，对处于 PREPARE 状态的事务，检查其对应的 Binlog 是否存在 —— 存在则提交，不存在则回滚，从而确保“有 Binlog 必有提交”，主从数据强一致。

# 锁

### 为什么要加锁？

当多个用户**并发地存取数据**时，在[数据库](https://cloud.tencent.com/solution/database?from=10680)中就会**产生多个事务同时存取同一数据的情况**。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。 保证多用户环境下保证数据库完整性和一致性。

### 讲一下Mysql里面有哪些锁？（按粒度分）

全局锁，行级锁，表级锁

全局锁就是给整个数据库上锁，使其处于一个只读状态，主要用于做全库数据备份。

**表级锁**

MySQL 中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。适用于大批量操作。

- 表锁：(除了会限制别的线程的读写外，也会限制本线程的读写
- 意向锁：（为了快速判断表里是否有记录被加锁），
- 元数据锁：（用来防止在curd的时候，有其他线程来修改数据表结构）。

**行级锁**：MySQL 中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。适用于对表中行数据频繁操作。

- 记录锁：锁住的是一条记录。
- 间隙锁（主要解决可重复读下的幻读现象），只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下的幻读现象。
- 临键锁：记录锁+间隙锁，锁定一个范围，并且锁定记录本身。

### 从锁的类别上分MySQL都有哪些锁呢？

从锁的类别上来讲，有共享锁和排他锁。

- 共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。
- 排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。

### 乐观锁和悲观锁

数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。

- 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制
- 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。

**两种锁的使用场景** 从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。 但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。

### select……for update会锁表还是锁行？

[MySQL update 语句加锁分析 - FrankYou - 博客园 (cnblogs.com)](https://www.cnblogs.com/frankyou/p/15271070.html)

加的是行锁还是表锁，这就要看是不是用了索引/主键。

没用索引/主键的话就是表锁，否则就是是行锁。

### 什么是死锁？怎么解决？

死锁是指两个或多个事务在不同资源上相互占用，并请求锁定对方的资源，不释放已有资源，从而导致恶性循环的现象。 常见的解决死锁的方法 1、如果不同程序会并发存取多个表，**尽量约定以相同的顺序访问表，可以大大降低死锁机会。** 2、在同一个事务中，尽可能做到**一次锁定所需要的所有资源**，减少死锁产生概率； 3、对于**非常容易产生死锁**的业务部分，可以尝试使用**升级锁定颗粒度，通过表级锁定来减少死锁产生的概率**； 如果业务处理不好可以用分布式事务锁或者使用乐观锁

### 死锁发生的条件

死锁只有同时满足以下四个条件才会发生：

·互斥条件：多个线程不能同时使用同一个资源。

·持有并等待条件：线程A在等待资源2的同时并不会释放自己已经持有的资源1。

·不可剥夺条件：在自己使用完当前资源之前不能被其他线程获取

·环路等待条件：两个线程获取资源的顺序构成了环形链。

### 优化锁方面的意见？

- 使用较低的隔离级别
- 设**计索引，尽量使用索引去访问数据，加锁更加精确**，从而减少锁冲突
- 选择合理的事务大小，给记录显示加锁时，最好一次性请求足够级别的锁。列如，修改数据的话，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，这样会导致死锁
- 不同的程序访问一组表的时候，应尽量约定一个相同的顺序访问各表，对于一个表而言，尽可能的固定顺序的获取表中的行。这样大大的减少死锁的机会。
- 尽量使用相等条件访问数据，这样可以避免间隙锁对并发插入的影响
- 不要申请超过实际需要的锁级别
- 数据查询的时候不是必要，不要使用加锁。MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能：MVCC只在committed read（读提交）和 repeatable read （可重复读）两种隔离级别
- 对于特定的事务，可以使用表锁来提高处理速度活着减少死锁的可能。

# 索引及其优化

### 索引是什么? 有什么好处？

索引类似于书籍的目录，可以**减少扫描的数据量**，提高查询效率。

如果查询的时候，没有用到索引就会全表扫描，这时候查询的**时间复杂度是O（n）**

如果用到了索引，那么查询的时候，可以基于**二分查找****算法**，通过索引快速定位到目标数据，mysql索引的数据结构一般是b+树，其搜索复杂度为O(logdN)，其中d表示节点允许的最大子节点个数为 d个。

### 索引的优缺点？

优点就是**查询速度快，效率高**。

缺点：

需要**占用物理空间**，数量越大，占用空间越大；

**创建索引和维护索引要耗费时间**，这种时间随着数量的增大而增大。

会**降低数据库的****增删查改****效率**，因为每次增删改索引，B+树为了维护有序性，都要进行动态维护。

### 讲讲索引的分类是什么？

MySQL可以按照四个角度来分类索引。

·按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。

·按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）。

·按「字段特性」分类：主键索引、唯一索引、**普通索引**、前缀索引。

·按「字段个数」分类：单列索引、联合索引。

注意：什么是前缀索引？

前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，目的是为了减少索引占用空间的大小，提升查询效率。

为什么减少索引占用空间的大小能提升查询效率？

能增加单个非叶子节点上的索引项数量，从而树的高度降低，宽度增加，减少IO次数，提高查询效率。

如何科学的选择前缀长度？

计算不同前缀的选择性，优先选选择性较高的前缀。

计算：去重后的前缀值个数 ÷ 总行数。

### MySQL聚簇索引和非聚簇索引的区别是什么？

**数据存储：**在聚簇索引中，数据行按照**索引键值的顺序**存储，也就是说，索引的叶子节点包含了实际的数据行。这意味着索引结构本身就是数据的物理存储结构。非聚簇索引的叶子节点不包含完整的数据行，而是包含**指向数据行的指针或****主键****值**。数据行本身存储在聚簇索引中。

**索引与数据关系：**聚簇索引查找数据时，可以直接从索引中获得数据行。当通过非聚簇索引可能需要"回表"。

**唯一性：**聚簇索引通常是基于主键构建的，因此**每个表只能有一个聚簇索引**，因为数据只能有**一种物理排序方式。一个表可以有多个非聚簇索引**，因为它们**不直接影响数据的物理存储位置。

**效率：**对于**范围查询和排序查询**，聚簇索引通常更有效率，因为它**避免了额外的寻址开销**。非聚簇索引在使用覆盖索引进行查询时效率更高，因为它不需要读取完整的数据行。如果不满足覆盖索引则需要进行回表的操作，使用非聚簇索引效率比较低，因为需要进行额外的回表操作。

### 如果聚簇索引的数据更新，它的存储要不要变化？

如果是更新的是非索引数据，也就是普通的用户记录，那么存储结构不会发生变化。

如果更新的是索引数据会发生变化，因为它要维护b+树的有序性。

### MySQL主键是聚簇索引吗？

是的，Innodb引擎中，其中主键索引的B+树就是所谓的聚簇索引。这意味着表中的数据行都存在b+树的叶子节点中。Innodb在创建聚簇索引时，会根据不同的情况选择不同的列作为索引：

1、如果有**主键**，直接用主键作为聚簇索引的索引键；

2、如果没有主键，则选择**第一个不为****null**的列作为聚簇索引的索引键；

3、以上两种情况都不成立的话，Innodb会自动生成一个**隐性的自增id**作为聚簇索引的索引键；

### 什么字段适合当做主键？

字段具有**唯一性**，且**不能为空**的特性。

字段最好的是**有递增的趋势的**，如果字段的值是随机无序的，可能会引发**页分裂**的问题，造成性能影响。

字段不建议用业务数据作为主键，比如会员卡号，订单号、学生号之类的，因为无法预测未来会不会因为业务需要，而出现业务字段重复或者重用的情况。

如果是多台机器就要考虑用分布式id的方案了。

### 自增ID,UUID,业务主键 作为主键各有什么优劣之处呢？

**自增ID** 性能最优、存储紧凑、插入高效，天然有序利于聚簇索引，但暴露业务量、不易分库；**UUID** 全局唯一、利于分布式，但无序导致页分裂、存储大、索引效率低；**业务****主键**（如订单号、手机号）语义清晰、避免冗余字段，但长度不可控、可能变更、易冲突。**推荐：单体用自增ID，分布式用雪花ID（折中方案），业务主键仅当稳定+唯一+短小时考虑。**

###  为什么索引结构默认使用B+Tree，而不是B-Tree，Hash，二叉树，红黑树？

在数据库索引结构中，B+树被广泛应用，相比于B树、哈希表、二叉树和红黑树等其他结构，B+树在多方面具有显著优势。以下是详细的对比和原因优化后的解释：

### B树 vs B+树

**时间复杂度**：B树的时间复杂度通常为O(log n)，其中n是节点数。这个复杂度是基于B树的高度与节点数的对数关系得出的。B树通过保持节点的平衡（即所有叶子节点位于同一层）来确保高效的搜索性能。 **B树**：

1. **节点数据存储**：B树的非叶子节点和叶子节点都存储数据，这导致非叶子节点的指针数量减少（也称为扇出变少）。在存储大量数据时，为了保持树的平衡，必须增加树的高度，从而增加I/O操作次数，降低查询性能。

**B+树**： **时间复杂度**：B+树的时间复杂度同样为O(log n)，但在某些情况下可能会表现为O(log m * log n)，其中m是节点的最大分支数。这种复杂度主要出现在考虑磁盘I/O操作的场景下。然而，在内存操作中，B+树的查询时间复杂度通常仍为O(log n)。

1. **磁盘读写代价低**：B+树的内部节点仅存储键值和子节点指针，而不存储具体数据。因此，内部节点更小，可以在一个盘块中存储更多的键值和指针。一旦读入内存，可以查找更多关键字，从而减少I/O操作次数。
2. **数据存储在叶子节点**：所有数据都存储在叶子节点，非叶子节点只存储索引信息。这样，数据的扫描和区间查询只需遍历叶子节点链表即可，不需要遍历整个树结构。这使得B+树更加适合范围查询。
3. **扇出更大**：由于非叶子节点更小，B+树的扇出更大，树的高度更低，从而减少I/O操作。

### B+树 vs 哈希表

**哈希表**：

1. **快速定位但无顺序**：哈希表可以在O(1)时间内进行等值查询，但不支持范围查询和有序访问，无法利用索引完成排序操作。
2. **I/O复杂度高**：哈希表在存储和检索时需要频繁进行哈希计算，I/O复杂度高。
3. **不支持部分匹配**：哈希索引必须匹配所有索引列，不能进行部分匹配查找。
4. **哈希碰撞问题**：大量重复键值会导致哈希碰撞，降低查询效率。

### B+树 vs 二叉树

**二叉树**：

1. **高度不均匀**：普通二叉树无法自平衡，随着数据量增加，树的高度可能变得不均匀，导致查询效率下降。
2. **I/O代价高**：树的高度增加会导致更多的I/O操作，影响性能。

### B+树 vs 红黑树

**时间复杂度**：红黑树的时间复杂度为O(log n)。这是因为它通过一系列旋转操作来维持树的平衡，确保树的高度保持在log n级别。 **红黑树**：

1. **树高度增加**：红黑树的高度随着数据量增加而增加，即使它是自平衡的，树的高度也相对较高。
2. **I/O代价高**：红黑树在存储大规模数据时，其I/O操作复杂度较高。

### 总结

**不使用平衡二叉树的主要原因**：

1. **深度太大**：平衡二叉树的每个节点最多只有两个子节点，导致树的深度较大。B+树由于扇出较大，深度较低，I/O复杂度为O(log_mN)。
2. **物理位置分散**：平衡二叉树的父子节点在逻辑上很近，但在物理存储上可能相距较远，无法充分利用磁盘顺序读和预读的高效特性。

综上所述，B+树在数据库索引中被广泛应用，因为它在**减少磁盘I/O次数、支持高效范围查询、存储密度高等方面具有显著优势**。相比于其他数据结构，B+树更能满足数据库系统对高效数据存储和检索的需求。

### 讲一下B+树的特性

所有叶子节点都在一层，确保了所有数据项的检索都具有**相同的****I/O****延迟**，提高了搜索效率。

每个叶子节点都包含指向相邻叶子节点的指针，**形成****双向链表****，适合范围查找和排序扫描**。

非叶子节点仅存储键值和指向子节点的指针，不包含数据记录，叶子节点存储实际数据记录或指向数据记录的指针。

自平衡：B+树在**插入、删除和更新**操作后会自动重新平衡，确保树的高度保持相对稳定，从而保持良好的搜索性能。

### Mysql为什么用B+树，和其他结构相比有什么优点？

B+树相比如B树来说，其叶子节点存储数据行，用双向链表连接，便于遍历查询和排序，而非叶子节点只存储索引键值和指针，在相同的I/O下能查询到更多的节点。

B+树对于二叉树来讲，对于N个节点的B+树的搜索时间复杂度是logdN，d是其节点允许的最大子节点个数。d值是大于100的，即使数据达到千万级别时，B+树的高度也就3,4层，也就是说一次查询做3,4次IO就可以找到数据，而二叉树每个父节点的最大子节点个数是2，导致搜索时间复杂度是log2N，这比B+树高出不少。

B+树对于hash结构来说，hash查询等值比较快，而不适合做范围查询。

### Redis 的索引为什么使用跳表而 MySQL 使用 B+树？

跳表适合内存搜索，而 B+ 适合磁盘搜索 ( 减少磁盘 I/O 次数 )

### B+ 树一般有多少层？可以存放多少行数据？

一般是 ==2 ~ 3 层==，可以存放约==两千万行==的数据。

### 在哪些情况下索引会失效？

索引失效常见于六类场景：**模糊查询左/全模糊（%xx）、对索引列使用函数或计算、隐式类型转换（字符串和数字作比较的时候）、违反最左匹配原则、OR 条件混用非索引列、以及范围查询(<,>)后接索引列**。

### 说一下B+树和B树的区别？

B+树的数据都存储在叶子节点上，非叶子节点存储索引信息；而B树的叶子结点和非叶子节点既存储索引信息还存储部分数据。

B+树的叶子结点用链表连接，**便于范围查询和顺序访问**；B树的叶子节点没有链表连接。

B+树的查找性能更稳定，每次查找都需要找到叶子结点；而B树的查找可能会在非叶子节点找到数据，性能不稳定。

### B+树的好处是什么？

B+树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索

引又存记录的B树，B+树的非叶子节点可以存放更多的索引，因此B+树可以比B树更「矮胖」，查

询底层节点的磁盘1/O次数会更少。

B+树叶子节点之间用链表连接了起来，有利于范围查询，而B树要实现范围查询，因此只能通过树的

遍历来完成范围查询，这会涉及多个节点的磁盘I/O操作，范围查询效率不如B+树。

由于数据全部集中在叶子层，插入和删除操作只需在叶子节点进行，非叶子节点仅维护索引路径，实现更清晰、更稳定。而 B 树的数据分布在整棵树，修改操作可能涉及多层节点，逻辑更复杂。

### 联合索引的实现原理？

将将多个字段组合成一个索引，该索引就被称为联合索引。走联合索引要满足**最左匹配原则**。在使用联合索引的时候如果不满足最左匹配原则，索引就会失效。因为联合索引在做查询时，会对比最左的字段，然后依次对比后面的字段。

### 创建联合索引时需要注意什么？

建立联合索引时的字段顺序，对索引效率也有很大影响。越靠前的字段被用于索引过滤的概率越高，实际开发工作中建立联合索引时，**要把区分度大的字段排在前面**，这样区分度大的字段越有可能被更多的SQL使用到。区分度为字段哪一列的不同值的个数除以总行数。

### 什么是覆盖索引？

**覆盖索引****是指一个索引包含了查询所需的所有列**，因此**不需要访问表中的数据行**就能完成查询。换句话说，查询所需的所有数据都能从索引中直接获取，而不需要进行回表查询。覆盖索引能够显著提高查询性能，因为减少了访问数据页的次数，从而减少了I/O操作。

### 什么时候适用索引？什么时候不适用？

适用：字段有**唯一性**；经常要用在**where**后面做查询使用的；然后需要用在**orderby ，groupby**后面做排序使用的字段；distinct字段；区分度高的列。

不适用：where、groupby、orderby里面用不到的字段；区分度较低的字段；表数据太少的时候；**经常更新的字段**；

# Mysql优化

### 为什么MySQL单表数据在2000W＋后会明显下降？

- **索引树的层级增加**：MySQL使用B+树作为索引结构(B+树的特点是叶子节点存放数据，非叶子结点存放键值和子节点指针)。当数据量增加时，B+树的层级会增加，导致在进行索引查找时需要遍历更多的节点。每一次遍历节点都会增加查询的I/O操作，从而导致查询性能下降。

- **磁盘I/O增加**：随着数据量的增加，索引和数据可能无法完全加载到内存中。每次查询需要更多的磁盘读取操作，而磁盘I/O是相对较慢的操作，导致查询性能下降。

  **总结一下：单表数据量越大，B+树高度越高，查询需要IO次数越多，性能越差。** 这里的几个分界值就是2W和2000W，也就是说1000W和100W通过主键来索引的性能其实是差不多的，都需要2次IO。 **详细介绍：**

- 最小储存单元：InnoDB存储引擎最小储存单元就是页（Page），页可以用于存放数据也可以用于存放键值+指针，一个页的大小默认是16K。也就是说InnoDB中不管你的数量量是多少，最终占用的存储空间肯定是16K的整数倍。
- B+树数据存储计算：这里假设单条纪录的数据大小为1K（一般的业务数据记录也就在1K左右），那么单个叶子结节所能存储的纪录数：16K/1K=16。非叶子节点能够存储多少指针呢？一般我们的主键ID都是bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样键值＋指针占用的大小就是14字节，一页能够存储的指针数：16K/14=1170。那么一棵高度为2的B+树能够存放的纪录数：1170_16=18720，一棵高度为3的B+树能够存放的纪录数：1170_1170*16＝21902400。在查找数据时，一次页的查找代表一次IO，而IO的字数又和B+树的高度有关，如果B+树为3层，那么通过主键索引数据时就需要3次IO，而IO的代价是非常高的，一般要控制在3以下，所以说一量数据量达到2000W+，那么B+树的高度将会变成4，从而导致每次主键索引都需要4次IO，IO次数的增加导致性能明显下降。

### 大表数据查询，怎么优化？

- 优化shema、sql语句+索引；
- 第二加缓存，memcached, redis；
- 主从复制，读写分离；
- 垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；
- 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；

### 超大分页怎么处理?

数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于select * from table where age > 20 limit 1000000,10 这种查询其实也是有可以优化的余地的. 这条语句需要 load1000000 数据然后基本上全部丢弃,只取 10 条当然比较慢. 当时我们可以修改为select * from table where id in (select id from table where age > 20 limit 1000000,10).这样虽然也 load 了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快。 **解决超大分页,其实主要是靠缓存,**可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可. 在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种. 【推荐】利用延迟关联或者子查询优化超多分页场景。 说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 正例：先快速定位需要获取的id段，然后再关联： SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id=b.id

### 如何优化关联查询？

- 确定ON或者USING子句中是否有索引。
- 确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。
- 保证被驱动表的JOIN字段已经创建了索引
- 需要JOIN 的字段，数据类型保持绝对一致。
- LEFT JOIN 时，选择小表作为驱动表， 大表作为被驱动表 。减少外层循环的次数。
- INNER JOIN 时，MySQL会自动将 小结果集的表选为驱动表 。选择相信MySQL优化策略。
- 能够直接多表关联的尽量直接关联，不用子查询。(减少查询的趟数)
- 不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或使用 JOIN 来代替子查询。

### 子查询优化

MySQL从4.1版本开始支持子查询，使用子查询可以进行SELECT语句的嵌套查询，即一个SELECT查询的结 果作为另一个SELECT语句的条件。 子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作 。

**子查询是 MySQL 的一项重要的功能，可以帮助我们通过一个 SQL 语句实现比较复杂的查询。但是，子** **查询的执行效率不高。**原因： ① 执行子查询时，MySQL需要为内层查询语句的查询结果 建立一个临时表 ，然后外层查询语句从临时表 中查询记录。查询完毕后，再 撤销这些临时表 。这样会消耗过多的CPU和IO资源，产生大量的慢查询。 ② 子查询的结果集存储的临时表，不论是内存临时表还是磁盘临时表都 不会存在索引 ，所以查询性能会 受到一定的影响。 ③ 对于返回结果集比较大的子查询，其对查询性能的影响也就越大。

**在MySQL中，可以使用连接（JOIN）查询来替代子查询**。连接查询 不需要建立临时表 ，其 速度比子查询 要快 ，如果查询中使用索引的话，性能就会更好。

> 结论：尽量不要使用NOT IN 或者 NOT EXISTS，用LEFT JOIN xxx ON xx WHERE xx IS NULL替代

### 在 MySQL 中统计数据表的行数，可以使用三种方式： SELECT COUNT(*) 、 SELECT COUNT(1) 和 SELECT COUNT(具体字段) ，使用这三者之间有什么区别？

#### 1️⃣ **语义区别（SQL 标准层面）**

- **`COUNT(*)`**：统计**所有行数**，不关心任何列的值，包括 NULL。这是 SQL 标准推荐的写法。
- **`COUNT(1)`**：统计所有行，因为常量 `1` 永远非 NULL，所以效果等同于 `COUNT(*)`。
- **`COUNT(字段)`**：只统计该**字段值非 NULL 的行数**。如果字段允许为 NULL，结果可能小于总行数。

#### 2️⃣ **执行机制（InnoDB 优化器层面）**

- MySQL 优化器非常智能，会将 `COUNT(*)`、`COUNT(1)` 和 `COUNT(主键)` **统一优化为相同的执行逻辑**。
- InnoDB 会选择**最小的可用索引**（通常是主键或某个二级索引）进行扫描，**只遍历索引的叶子节点**，无需回表读取完整数据行。
- 只要字段**非 NULL（如主键）**，`COUNT(字段)` 也会被优化成和 `COUNT(*)` 一样的计划。

#### 3️⃣ **性能差异（关键！）**

- **`COUNT(\*)` / `COUNT(1)` / `COUNT(非空字段)`**：✅ **性能几乎无差别**。
- `COUNT(可为空的字段)`：⚠️ 可能显著变慢！
  - 因为需要判断字段是否为 NULL；
  - 如果该字段**没有索引**，会导致全表扫描数据页，I/O 大增。

总结：**在 InnoDB 中，只要不涉及 NULL 判断，三者性能无异；但从代码可读性和标准性出发，应首选 `COUNT(\*)`**

### 分库分表

[![img](https://camo.githubusercontent.com/16d2886aa4ab2dd625024eb5966c72fc96adce6b4ffc3b4deeeddf1013a32e43/68747470733a2f2f706963332e7a68696d672e636f6d2f76322d64353762663732326634333732363235646639393132636433306264613835365f722e6a7067)](https://camo.githubusercontent.com/16d2886aa4ab2dd625024eb5966c72fc96adce6b4ffc3b4deeeddf1013a32e43/68747470733a2f2f706963332e7a68696d672e636f6d2f76322d64353762663732326634333732363235646639393132636433306264613835365f722e6a7067)

#### 垂直分表

垂直分表：**将一个表按照字段分成多个表** ，每个表存储其中一部分字段。

根据数据是否是热点数据划分。热点数据即经常查询、更新频繁的列。

例如一个订单状态信息会频繁进行更新、订单金额在列表会频繁被查询到作为热点数据，而下单地址、手机号码等信息基本不会改变或者改变次数很少作为非热点数据。

##### 好处

1. 更好地提升热门数据的查询效率。
2. 行数据变小，数据库IO效率高。

#### 水平分表

水平分表：把同一个表的数据按照一定规则拆分到多个表中（基于数据划分，表结构相同）。一般意义上的分库分表指的就是水平分表。

##### 策略

1. 范围切分：每个表存放1000w数据，满了再建新表。
   - 优点：后续扩容方便，无需进行数据迁移
   - 缺点：读写流量全集中在最新的表上，没有起到流量均摊的效果
   - 适用场景：归档类功能，比如操作日志按日期分表，每个月一张表
2. 中间表映射（路由表）：每次先查路由表确定完整数据所在的库表，再到该库表查完整数据。
   - 优点：灵活，可以随意设置路由规则
   - 缺点：引入了额外的单点查询，路由表也可能非常大，又存在分库分表的问题
   - 适用场景：对数据量特别大的用户，为其建立路由规则，单独放到一张大表中，其他普通用户还走正常的hash切分逻辑
3. Hash切分：对分表键进行一定的运算（通常是取模），从而决定路由到哪个库哪个表。
   - 优点：数据分片与读写流量分摊都比较均匀
   - 缺点：可能存在跨节点查询和分页等问题
   - 适用场景：目前大多数互联网服务使用的都是hash切分

#### 分库分表存在的问题

1. 分布式事务问题

   在提交订单时，除了创建订单之外，我们还需要扣除相应的库存。而订单表和库存表由于垂直分库，位于不同的库中，这时我们需要通过分布式事务来保证提交订单时的事务完整性。

2. 跨节点 JOIN 查询问题

   用户在查询订单时，我们往往需要通过表连接获取到商品信息，而商品信息表可能在另外一个库中。

   解决该问题的普遍做法是分两次查询实现：在第一次查询的结果集中找出关联数据的id，根据这些id发起第二次请求得到关联数据。

   **字段冗余**：把需要关联的字段放入主表中，避免 join 操作。

3. 跨节点排序、分页、函数计算问题

   由于这类问题都需要基于全部数据集合进行计算。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和 join 不同的是每个结点的查询可以并行执行，因此速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。

4. 全局主键 ID 问题

   1. UUID 实现全局 ID

      - 优点：本地生成ID，不需要远程调用，全局唯一不重复。
      - 缺点：占用空间大，连续性差，不适合作为主键索引。

   2. redis 生成 ID

      基于 Redis 分布式锁实现一个递增的主键 ID，这种方式可以保证主键是一个整数且有一定的连续性，但分布式锁存在一定的性能消耗。

   3. 数据库自增 ID

      在分库分表表后使用数据库自增ID，需要一个专门用于生成主键的库，每次服务接收到请求，先向这个库中插入一条没有意义的数据，获取一个数据库自增的ID，利用这个ID去分库分表中写数据。

   4. SnowFlake（雪花算法）

      在分布式系统中产生全局唯一且趋势递增的ID，值类型为64位长整型。

      > 1. 第1位始终为0，可以看作是符号位不可用；
      > 2. 第2位开始的41位是毫秒级时间戳，可用年限为69年；
      > 3. 中间的10位表示机器数，即2^10=1024台机器；
      > 4. 最后12位是自增序列，2^12=4096个数。

# 架构

### 你能讲一下Mysql的主从同步嘛？

mysql主从复制主要依赖于**binlog**，也就是记录mysql上的所有变化并以**二进制形式**保存在磁盘上。复制的过程就是将binlog中的数据从主库上传输到从库上。这个过程一般是**异步的**，也就是主库上执行事务操作的线程不会等待复制binlog的线程同步完成。

mysql集群的主从复制过程梳理成3个阶段：

1、写入binlog：主库写入binlog日志，提交事务，并更新本地存储数据。

2、同步binlog：把binlog日志同步到所有从库上去，每个从库把binlog写入到暂存日志中。

3、回放binlog：从库回放binlog，并更新存储引擎中的数据。

### **MySQL****主从同步的目的？为什么要做主从同步？**

1. **通过增加从服务器来提高数据库的性能**，在主服务器上执行**写入和更新**，在从服务器上**向外提供读功能**，可以动态地调整从服务器的数量，从而调整整个数据库的性能。
2. **提高数据安全**-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据
3. **在主服务器上生成实时数据**，而在从服务器上分析这些数据，从而提高主服务器的性能
4. **数据备份**。一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全

### **如何实现****MySQL****的读写分离？**

其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。

### 主从延迟都有什么处理方法？

强制走主库方案：对于大事务或资源密集型操作，直接在主库上执行，避免从库的额外延迟。

### 主从复制延迟的原因是什么？有什么解决方案吗？

主要原因是从库的单线程回放操作跟不上主库的并发写入，尤其是在大事务、DDL或从库性能不足时加剧；解决方案包括启用**并行****复制**、**拆分大事务**（比如应用层拆分批量操作）、**优化从库配置**（提升从库硬件、调整 InnoDB 参数）等。
